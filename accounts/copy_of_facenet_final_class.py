# -*- coding: utf-8 -*-
"""Copy of FaceNet_Final_Class.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xhCMbQ8G7UV5dn2pTSMrpj60_MpwnWvv

#Data Prep

###Installing libraries
"""
import glob
import os
import time
from os import listdir, makedirs

import cv2
import deepface
import gdown
import numpy as np
import pandas as pd
import PIL
import tensorflow as tf
from deepface import DeepFace
from deepface.commons import functions
from PIL import Image

from Gp_Backend.settings import FOLDER4_PATH

# --------------------------------
# dependency configuration

tf_version = int(tf.__version__.split(".", maxsplit=1)[0])

if tf_version == 1:
    from keras import backend as K
    from keras.layers import (
        Activation,
        BatchNormalization,
        Concatenate,
        Conv2D,
        Dense,
        Dropout,
        GlobalAveragePooling2D,
        Input,
        Lambda,
        MaxPooling2D,
        add,
    )
    from keras.models import Model
else:
    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Activation
    from tensorflow.keras.layers import BatchNormalization
    from tensorflow.keras.layers import Concatenate
    from tensorflow.keras.layers import Conv2D
    from tensorflow.keras.layers import Dense
    from tensorflow.keras.layers import Dropout
    from tensorflow.keras.layers import GlobalAveragePooling2D
    from tensorflow.keras.layers import Input
    from tensorflow.keras.layers import Lambda
    from tensorflow.keras.layers import MaxPooling2D
    from tensorflow.keras.layers import add
    from tensorflow.keras import backend as K

from pathlib import Path

import gdown

tf_version = int(tf.__version__.split(".")[0])

if tf_version == 1:
    from keras.layers import (
        Add,
        BatchNormalization,
        Conv2D,
        Input,
        MaxPool2D,
        ReLU,
        Softmax,
        UpSampling2D,
        ZeroPadding2D,
        concatenate,
    )
    from keras.models import Model

else:
    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import (
        Input,
        BatchNormalization,
        ZeroPadding2D,
        Conv2D,
        ReLU,
        MaxPool2D,
        Add,
        UpSampling2D,
        concatenate,
        Softmax,
    )

import base64
import logging
import pickle
import time
import warnings
from os import path

# package dependencies
from deepface.basemodels import Facenet
from deepface.commons import distance as dst
from deepface.commons import functions, realtime

# 3rd party dependencies
from tqdm import tqdm

tf_version = tf.__version__
tf_major_version = int(tf_version.split(".", maxsplit=1)[0])
tf_minor_version = int(tf_version.split(".")[1])

if tf_major_version == 1:
    from keras.preprocessing import image
elif tf_major_version == 2:
    from tensorflow.keras.preprocessing import image

import requests
from deepface.detectors.FaceDetector import detect_faces

"""# Model Layers"""


def scaling(x, scale):
    return x * scale


"""#Model"""


# def load_Facenet_Model():
#     model = MyInceptionResNetV2()
#     # -----------------------------------
#     # Add the pass of facenet_weights.h5 file
#     facenet_file2 = os.path.join(FOLDER4_PATH, "facenet_weights.h5")
#     model.load_weights(facenet_file2)
#     # -----------------------------------
#     return model

def load_Facenet_Model():
    global model_obj

    #model = MyInceptionResNetV2()
    # -----------------------------------
    # Add the pass of facenet_weights.h5 file
    #model = load_model('content/facenet.keras')
    model_name = "Facenet"

    models = {
        "Facenet": Facenet.loadModel,
     
    }

    if not "model_obj" in globals():
        model_obj = {}

    if not model_name in model_obj:
        model = models.get(model_name)
        if model:
            model = model()
            model_obj[model_name] = model
        else:
            raise ValueError(f"Invalid model_name passed - {model_name}")

    # -----------------------------------
    return  model_obj["Facenet"]

# def extract_faces_initial(img_path, target_size=(160, 160), detector_backend="retinaface",enforce_detection=True,align=True,grayscale=False):

#   resp_objs = []
#   img_objs = functions.extract_faces(
#       img=img_path,
#       target_size=target_size,
#       detector_backend=detector_backend,
#       grayscale=grayscale,
#       enforce_detection=enforce_detection,
#       align=align,
#   )

#   for img, region, confidence in img_objs:
#       resp_obj = {}

#       # discard expanded dimension
#       if len(img.shape) == 4:
#           img = img[0]
#       resp_obj["face"] = img[:, :, ::-1]
#       resp_obj["facial_area"] = region
#       resp_obj["confidence"] = confidence
#       resp_objs.append(resp_obj)
#   return resp_objs


def detect_largest_face(faces):
    largest_face_area = 0
    largest_face_img = None
    for i in range(len(faces)):
        face_img = faces[i][0]
        face_area = face_img.shape[0] * face_img.shape[1]
        if face_area > largest_face_area:
            largest_face_area = face_area
            largest_face_img = face_img

    return largest_face_img


"""# extract faces next layer"""


def loadBase64Img(uri):
    encoded_data = uri.split(",")[1]
    nparr = np.fromstring(base64.b64decode(encoded_data), np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    return img


def load_image(img):
    exact_image = False
    base64_img = False
    url_img = False

    if type(img).__module__ == np.__name__:
        exact_image = True

    elif img.startswith("data:image/"):
        base64_img = True

    elif img.startswith("http"):
        url_img = True

    # ---------------------------

    if base64_img is True:
        img = loadBase64Img(img)

    elif url_img is True:
        img = np.array(Image.open(requests.get(img, stream=True, timeout=60).raw).convert("RGB"))

    elif exact_image is not True:  # image path passed as input
        if os.path.isfile(img) is not True:
            raise ValueError(f"Confirm that {img} exists")

        img = cv2.imread(img)

    return img


def extract_faces(
    img,
    target_size=(160, 160),
    detector_backend="retinaface",
    grayscale=False,
    enforce_detection=True,
    align=True,
):
    # this is going to store a list of img itself (numpy), it region and confidence
    extracted_faces = []

    # img might be path, base64 or numpy array. Convert it to numpy whatever it is.
    img = load_image(img)
    img_region = [0, 0, img.shape[1], img.shape[0]]

    if detector_backend == "skip":
        face_objs = [(img, img_region, 0)]
    else:
        face_detector = build_retinaface_model()
        face_objs = detect_faces(face_detector, detector_backend, img, align)

    # in case of no face found
    if len(face_objs) == 0 and enforce_detection is True:
        # raise ValueError(
        #     "Face could not be detected. Please confirm that the picture is a face photo "
        #     + "or consider to set enforce_detection param to False."
        # )
        return extracted_faces

    if len(face_objs) == 0 and enforce_detection is False:
        face_objs = [(img, img_region, 0)]

    for current_img, current_region, confidence in face_objs:
        if current_img.shape[0] > 0 and current_img.shape[1] > 0:
            if grayscale is True:
                current_img = cv2.cvtColor(current_img, cv2.COLOR_BGR2GRAY)

            # resize and padding
            if current_img.shape[0] > 0 and current_img.shape[1] > 0:
                factor_0 = target_size[0] / current_img.shape[0]
                factor_1 = target_size[1] / current_img.shape[1]
                factor = min(factor_0, factor_1)

                dsize = (int(current_img.shape[1] * factor), int(current_img.shape[0] * factor))
                current_img = cv2.resize(current_img, dsize)

                diff_0 = target_size[0] - current_img.shape[0]
                diff_1 = target_size[1] - current_img.shape[1]
                if grayscale is False:
                    # Put the base image in the middle of the padded image
                    current_img = np.pad(
                        current_img,
                        (
                            (diff_0 // 2, diff_0 - diff_0 // 2),
                            (diff_1 // 2, diff_1 - diff_1 // 2),
                            (0, 0),
                        ),
                        "constant",
                    )
                else:
                    current_img = np.pad(
                        current_img,
                        ((diff_0 // 2, diff_0 - diff_0 // 2), (diff_1 // 2, diff_1 - diff_1 // 2)),
                        "constant",
                    )

            # double check: if target image is not still the same size with target.
            if current_img.shape[0:2] != target_size:
                current_img = cv2.resize(current_img, target_size)

            # normalizing the image pixels
            img_pixels = image.img_to_array(current_img)  # what this line doing? must?
            img_pixels = np.expand_dims(img_pixels, axis=0)
            img_pixels /= 255  # normalize input in [0, 1]

            # int cast is for the exception - object of type 'float32' is not JSON serializable
            region_obj = {
                "x": int(current_region[0]),
                "y": int(current_region[1]),
                "w": int(current_region[2]),
                "h": int(current_region[3]),
            }

            extracted_face = [img_pixels, region_obj, confidence]
            extracted_faces.append(extracted_face)

    if len(extracted_faces) == 0 and enforce_detection == True:
        raise ValueError(f"Detected face shape is {img.shape}. Consider to set enforce_detection arg to False.")

    return extracted_faces


"""###Create representations"""


def create_represenation_file(
    db_path,
    distance_metric="cosine",
    enforce_detection=True,
    detector_backend="retinaface",
    align=True,
    normalization="base",
    silent=False,
):
    # check if the file contain images
    employees = []

    for r, _, f in os.walk(db_path):
        for file in f:
            if (".jpg" in file.lower()) or (".jpeg" in file.lower()) or (".png" in file.lower()):
                exact_path = r + "/" + file
                employees.append(exact_path)

    if len(employees) == 0:
        raise ValueError(
            "There is no image in ",
            db_path,
            " folder! Validate .jpg or .png files exist in this path.",
        )

    # ------------------------
    # find representations for db images

    representations = []

    # for employee in employees:
    pbar = tqdm(
        range(0, len(employees)),
        desc="Finding representations",
        disable=silent,
    )
    for index in pbar:
        employee = employees[index]
        img_objs = extract_faces(
            img=employee,
            target_size=(160, 160),
            detector_backend=detector_backend,
            grayscale=False,
            enforce_detection=enforce_detection,
            align=align,
        )
        objects = detect_largest_face(img_objs)
        for img_content, _, _ in img_objs:
            embedding_obj = represent(
                img_path=img_content,
                model_name="Facenet",
                enforce_detection=enforce_detection,
                detector_backend="skip",
                align=align,
                normalization=normalization,
            )

            img_representation = embedding_obj[0]["embedding"]

            instance = []
            instance.append(employee)
            instance.append(img_representation)
            representations.append(instance)

    if not silent:
        print("representations found are: ", len(representations))

    return representations


"""###Find a face"""


def Facenet_find(
    img_path,
    db_path,
    model_name="Facenet",
    distance_metric="cosine",
    enforce_detection=True,
    detector_backend="retinaface",
    align=True,
    normalization="base",
    silent=False,
):
    tic = time.time()

    # -------------------------------
    if os.path.isdir(db_path) is not True:
        raise ValueError("Passed db_path does not exist!")

    target_size = (160, 160)

    # ---------------------------------------

    file_name = f"representations_{model_name}.pkl"
    file_name = file_name.replace("-", "_").lower()

    if path.exists(db_path + "/" + file_name):
        if not silent:
            print(
                f"WARNING: Representations for images in {db_path} folder were previously stored"
                + f" in {file_name}. If you added new instances after the creation, then please "
                + "delete this file and call find function again. It will create it again."
            )

        with open(f"{db_path}/{file_name}", "rb") as f:
            representations = pickle.load(f)
            f.close()

        if not silent:
            print("There are ", len(representations), " representations found in ", file_name)

    else:  # create representation.pkl from scratch
        representations = create_represenation_file(db_path)
        # -------------------------------

        with open(f"{db_path}/{file_name}", "wb") as f:
            pickle.dump(representations, f)
            f.close()

        if not silent:
            print(
                f"Representations stored in {db_path}/{file_name} file."
                + "Please delete this file when you add new identities in your database."
            )

    # ----------------------------
    # now, we got representations for facial database
    df = pd.DataFrame(representations, columns=["identity", f"{model_name}_representation"])
    # img path might have more than once face
    target_objs = extract_faces(
        img=img_path,
        target_size=target_size,
        detector_backend=detector_backend,
        grayscale=False,
        enforce_detection=enforce_detection,
        align=align,
    )

    if target_objs:
        resp_obj = []

        target_img = detect_largest_face(target_objs)

        target_embedding_obj = represent(
            img_path=target_img,
            model_name=model_name,
            enforce_detection=enforce_detection,
            detector_backend="skip",
            align=align,
            normalization=normalization,
        )

        target_representation = target_embedding_obj[0]["embedding"]

        result_df = df.copy()  # df will be filtered in each img
        distances = []
        for index, instance in df.iterrows():
            source_representation = instance[f"{model_name}_representation"]

            if distance_metric == "cosine":
                distance = dst.findCosineDistance(source_representation, target_representation)

            else:
                raise ValueError(f"invalid distance metric passes - {distance_metric}")

            distances.append(distance)

            # ---------------------------

        result_df[f"{model_name}_{distance_metric}"] = distances

        threshold = dst.findThreshold(model_name, distance_metric)
        result_df = result_df.drop(columns=[f"{model_name}_representation"])
        result_df = result_df[result_df[f"{model_name}_{distance_metric}"] <= threshold]
        result_df = result_df.sort_values(by=[f"{model_name}_{distance_metric}"], ascending=True).reset_index(drop=True)

        resp_obj.append(result_df)

        # -----------------------------------

    else:
        target_representation = []

        if not silent:
            print("no face detected")
            return "no face detected", target_representation

    toc = time.time()

    if not silent:
        print("find function lasts ", toc - tic, " seconds")

    if result_df.empty:
        return False, target_representation

    recognized_final = str(result_df["identity"][0])
    return recognized_final, target_representation


"""###Add a new representation"""


def add_new_representation(img_path, target_representation, db_path):
    file_name = f"representations_facenet.pkl"

    resp_obj = []

    instance = []
    instance.append(img_path)
    instance.append(target_representation)
    with open(f"{db_path}/{file_name}", "rb") as f:
        representations = pickle.load(f)
        f.close()

    representations.append(instance)

    with open(f"{db_path}/{file_name}", "wb") as f:
        pickle.dump(representations, f)
        f.close()


"""###Represent a face"""


def represent(
    img_path, model_name="Facenet", enforce_detection=True, detector_backend="skip", align=True, normalization="base"
):
    resp_objs = []

    model = load_Facenet_Model()

    # ---------------------------------
    # we have run pre-process in verification. so, this can be skipped if it is coming from verify.
    target_size = (160, 160)
    if detector_backend != "skip":
        img_objs = extract_faces(
            img=img_path,
            target_size=target_size,
            detector_backend=detector_backend,
            grayscale=False,
            enforce_detection=enforce_detection,
            align=align,
        )
    else:  # skip
        if isinstance(img_path, str):
            img = functions.load_image(img_path)
        elif type(img_path).__module__ == np.__name__:
            img = img_path.copy()
        else:
            raise ValueError(f"unexpected type for img_path - {type(img_path)}")
        # --------------------------------
        if len(img.shape) == 4:
            img = img[0]  # e.g. (1, 224, 224, 3) to (224, 224, 3)
        if len(img.shape) == 3:
            img = cv2.resize(img, target_size)
            img = np.expand_dims(img, axis=0)
        # --------------------------------
        img_region = [0, 0, img.shape[1], img.shape[0]]
        img_objs = [(img, img_region, 0)]
    # ---------------------------------

    for img, region, _ in img_objs:
        # custom normalization
        img = functions.normalize_input(img=img, normalization=normalization)

        # represent
        if "keras" in str(type(model)):
            # new tf versions show progress bar and it is annoying
            embedding = model.predict(img, verbose=0)[0].tolist()
        else:
            # SFace and Dlib are not keras models and no verbose arguments
            embedding = model.predict(img)[0].tolist()

        resp_obj = {}
        resp_obj["embedding"] = embedding
        resp_obj["facial_area"] = region
        resp_objs.append(resp_obj)

    return resp_objs


"""#RetinaFace Model loading

###load weights
"""


# def load_retinaface_weights(model):
#     exact_file = os.path.join(FOLDER4_PATH, "retinaface.h5")
#     model.load_weights(exact_file)

#     return model

def build_model():
    
    global model #singleton design pattern
    
    if not "model" in globals():
        
        model = tf.function(
            build_retinaface_model(),
            input_signature=(tf.TensorSpec(shape=[None, None, None, 3], dtype=np.float32),)
        )


    return model


def load_weights(model):
    exact_file = os.path.join(FOLDER4_PATH, "retinaface.h5")
    model.load_weights(exact_file)
    return model


"""###load model layers"""


def build_retinaface_model():
    data = Input(dtype=tf.float32, shape=(None, None, 3), name="data")

    bn_data = BatchNormalization(epsilon=1.9999999494757503e-05, name="bn_data", trainable=False)(data)

    conv0_pad = ZeroPadding2D(padding=tuple([3, 3]))(bn_data)

    conv0 = Conv2D(filters=64, kernel_size=(7, 7), name="conv0", strides=[2, 2], padding="VALID", use_bias=False)(conv0_pad)

    bn0 = BatchNormalization(epsilon=1.9999999494757503e-05, name="bn0", trainable=False)(conv0)

    relu0 = ReLU(name="relu0")(bn0)

    pooling0_pad = ZeroPadding2D(padding=tuple([1, 1]))(relu0)

    pooling0 = MaxPool2D((3, 3), (2, 2), padding="VALID", name="pooling0")(pooling0_pad)

    stage1_unit1_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit1_bn1", trainable=False)(pooling0)

    stage1_unit1_relu1 = ReLU(name="stage1_unit1_relu1")(stage1_unit1_bn1)

    stage1_unit1_conv1 = Conv2D(
        filters=64, kernel_size=(1, 1), name="stage1_unit1_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit1_relu1)

    stage1_unit1_sc = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage1_unit1_sc", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit1_relu1)

    stage1_unit1_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit1_bn2", trainable=False)(
        stage1_unit1_conv1
    )

    stage1_unit1_relu2 = ReLU(name="stage1_unit1_relu2")(stage1_unit1_bn2)

    stage1_unit1_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage1_unit1_relu2)

    stage1_unit1_conv2 = Conv2D(
        filters=64, kernel_size=(3, 3), name="stage1_unit1_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit1_conv2_pad)

    stage1_unit1_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit1_bn3", trainable=False)(
        stage1_unit1_conv2
    )

    stage1_unit1_relu3 = ReLU(name="stage1_unit1_relu3")(stage1_unit1_bn3)

    stage1_unit1_conv3 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage1_unit1_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit1_relu3)

    plus0_v1 = Add()([stage1_unit1_conv3, stage1_unit1_sc])

    stage1_unit2_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit2_bn1", trainable=False)(plus0_v1)

    stage1_unit2_relu1 = ReLU(name="stage1_unit2_relu1")(stage1_unit2_bn1)

    stage1_unit2_conv1 = Conv2D(
        filters=64, kernel_size=(1, 1), name="stage1_unit2_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit2_relu1)

    stage1_unit2_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit2_bn2", trainable=False)(
        stage1_unit2_conv1
    )

    stage1_unit2_relu2 = ReLU(name="stage1_unit2_relu2")(stage1_unit2_bn2)

    stage1_unit2_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage1_unit2_relu2)

    stage1_unit2_conv2 = Conv2D(
        filters=64, kernel_size=(3, 3), name="stage1_unit2_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit2_conv2_pad)

    stage1_unit2_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit2_bn3", trainable=False)(
        stage1_unit2_conv2
    )

    stage1_unit2_relu3 = ReLU(name="stage1_unit2_relu3")(stage1_unit2_bn3)

    stage1_unit2_conv3 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage1_unit2_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit2_relu3)

    plus1_v2 = Add()([stage1_unit2_conv3, plus0_v1])

    stage1_unit3_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit3_bn1", trainable=False)(plus1_v2)

    stage1_unit3_relu1 = ReLU(name="stage1_unit3_relu1")(stage1_unit3_bn1)

    stage1_unit3_conv1 = Conv2D(
        filters=64, kernel_size=(1, 1), name="stage1_unit3_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit3_relu1)

    stage1_unit3_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit3_bn2", trainable=False)(
        stage1_unit3_conv1
    )

    stage1_unit3_relu2 = ReLU(name="stage1_unit3_relu2")(stage1_unit3_bn2)

    stage1_unit3_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage1_unit3_relu2)

    stage1_unit3_conv2 = Conv2D(
        filters=64, kernel_size=(3, 3), name="stage1_unit3_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit3_conv2_pad)

    stage1_unit3_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage1_unit3_bn3", trainable=False)(
        stage1_unit3_conv2
    )

    stage1_unit3_relu3 = ReLU(name="stage1_unit3_relu3")(stage1_unit3_bn3)

    stage1_unit3_conv3 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage1_unit3_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage1_unit3_relu3)

    plus2 = Add()([stage1_unit3_conv3, plus1_v2])

    stage2_unit1_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit1_bn1", trainable=False)(plus2)

    stage2_unit1_relu1 = ReLU(name="stage2_unit1_relu1")(stage2_unit1_bn1)

    stage2_unit1_conv1 = Conv2D(
        filters=128, kernel_size=(1, 1), name="stage2_unit1_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit1_relu1)

    stage2_unit1_sc = Conv2D(
        filters=512, kernel_size=(1, 1), name="stage2_unit1_sc", strides=[2, 2], padding="VALID", use_bias=False
    )(stage2_unit1_relu1)

    stage2_unit1_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit1_bn2", trainable=False)(
        stage2_unit1_conv1
    )

    stage2_unit1_relu2 = ReLU(name="stage2_unit1_relu2")(stage2_unit1_bn2)

    stage2_unit1_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage2_unit1_relu2)

    stage2_unit1_conv2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="stage2_unit1_conv2", strides=[2, 2], padding="VALID", use_bias=False
    )(stage2_unit1_conv2_pad)

    stage2_unit1_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit1_bn3", trainable=False)(
        stage2_unit1_conv2
    )

    stage2_unit1_relu3 = ReLU(name="stage2_unit1_relu3")(stage2_unit1_bn3)

    stage2_unit1_conv3 = Conv2D(
        filters=512, kernel_size=(1, 1), name="stage2_unit1_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit1_relu3)

    plus3 = Add()([stage2_unit1_conv3, stage2_unit1_sc])

    stage2_unit2_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit2_bn1", trainable=False)(plus3)

    stage2_unit2_relu1 = ReLU(name="stage2_unit2_relu1")(stage2_unit2_bn1)

    stage2_unit2_conv1 = Conv2D(
        filters=128, kernel_size=(1, 1), name="stage2_unit2_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit2_relu1)

    stage2_unit2_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit2_bn2", trainable=False)(
        stage2_unit2_conv1
    )

    stage2_unit2_relu2 = ReLU(name="stage2_unit2_relu2")(stage2_unit2_bn2)

    stage2_unit2_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage2_unit2_relu2)

    stage2_unit2_conv2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="stage2_unit2_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit2_conv2_pad)

    stage2_unit2_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit2_bn3", trainable=False)(
        stage2_unit2_conv2
    )

    stage2_unit2_relu3 = ReLU(name="stage2_unit2_relu3")(stage2_unit2_bn3)

    stage2_unit2_conv3 = Conv2D(
        filters=512, kernel_size=(1, 1), name="stage2_unit2_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit2_relu3)

    plus4 = Add()([stage2_unit2_conv3, plus3])

    stage2_unit3_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit3_bn1", trainable=False)(plus4)

    stage2_unit3_relu1 = ReLU(name="stage2_unit3_relu1")(stage2_unit3_bn1)

    stage2_unit3_conv1 = Conv2D(
        filters=128, kernel_size=(1, 1), name="stage2_unit3_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit3_relu1)

    stage2_unit3_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit3_bn2", trainable=False)(
        stage2_unit3_conv1
    )

    stage2_unit3_relu2 = ReLU(name="stage2_unit3_relu2")(stage2_unit3_bn2)

    stage2_unit3_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage2_unit3_relu2)

    stage2_unit3_conv2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="stage2_unit3_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit3_conv2_pad)

    stage2_unit3_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit3_bn3", trainable=False)(
        stage2_unit3_conv2
    )

    stage2_unit3_relu3 = ReLU(name="stage2_unit3_relu3")(stage2_unit3_bn3)

    stage2_unit3_conv3 = Conv2D(
        filters=512, kernel_size=(1, 1), name="stage2_unit3_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit3_relu3)

    plus5 = Add()([stage2_unit3_conv3, plus4])

    stage2_unit4_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit4_bn1", trainable=False)(plus5)

    stage2_unit4_relu1 = ReLU(name="stage2_unit4_relu1")(stage2_unit4_bn1)

    stage2_unit4_conv1 = Conv2D(
        filters=128, kernel_size=(1, 1), name="stage2_unit4_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit4_relu1)

    stage2_unit4_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit4_bn2", trainable=False)(
        stage2_unit4_conv1
    )

    stage2_unit4_relu2 = ReLU(name="stage2_unit4_relu2")(stage2_unit4_bn2)

    stage2_unit4_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage2_unit4_relu2)

    stage2_unit4_conv2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="stage2_unit4_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit4_conv2_pad)

    stage2_unit4_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage2_unit4_bn3", trainable=False)(
        stage2_unit4_conv2
    )

    stage2_unit4_relu3 = ReLU(name="stage2_unit4_relu3")(stage2_unit4_bn3)

    stage2_unit4_conv3 = Conv2D(
        filters=512, kernel_size=(1, 1), name="stage2_unit4_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage2_unit4_relu3)

    plus6 = Add()([stage2_unit4_conv3, plus5])

    stage3_unit1_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit1_bn1", trainable=False)(plus6)

    stage3_unit1_relu1 = ReLU(name="stage3_unit1_relu1")(stage3_unit1_bn1)

    stage3_unit1_conv1 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage3_unit1_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit1_relu1)

    stage3_unit1_sc = Conv2D(
        filters=1024, kernel_size=(1, 1), name="stage3_unit1_sc", strides=[2, 2], padding="VALID", use_bias=False
    )(stage3_unit1_relu1)

    stage3_unit1_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit1_bn2", trainable=False)(
        stage3_unit1_conv1
    )

    stage3_unit1_relu2 = ReLU(name="stage3_unit1_relu2")(stage3_unit1_bn2)

    stage3_unit1_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage3_unit1_relu2)

    stage3_unit1_conv2 = Conv2D(
        filters=256, kernel_size=(3, 3), name="stage3_unit1_conv2", strides=[2, 2], padding="VALID", use_bias=False
    )(stage3_unit1_conv2_pad)

    ssh_m1_red_conv = Conv2D(
        filters=256, kernel_size=(1, 1), name="ssh_m1_red_conv", strides=[1, 1], padding="VALID", use_bias=True
    )(stage3_unit1_relu2)

    stage3_unit1_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit1_bn3", trainable=False)(
        stage3_unit1_conv2
    )

    ssh_m1_red_conv_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name="ssh_m1_red_conv_bn", trainable=False)(
        ssh_m1_red_conv
    )

    stage3_unit1_relu3 = ReLU(name="stage3_unit1_relu3")(stage3_unit1_bn3)

    ssh_m1_red_conv_relu = ReLU(name="ssh_m1_red_conv_relu")(ssh_m1_red_conv_bn)

    stage3_unit1_conv3 = Conv2D(
        filters=1024, kernel_size=(1, 1), name="stage3_unit1_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit1_relu3)

    plus7 = Add()([stage3_unit1_conv3, stage3_unit1_sc])

    stage3_unit2_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit2_bn1", trainable=False)(plus7)

    stage3_unit2_relu1 = ReLU(name="stage3_unit2_relu1")(stage3_unit2_bn1)

    stage3_unit2_conv1 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage3_unit2_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit2_relu1)

    stage3_unit2_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit2_bn2", trainable=False)(
        stage3_unit2_conv1
    )

    stage3_unit2_relu2 = ReLU(name="stage3_unit2_relu2")(stage3_unit2_bn2)

    stage3_unit2_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage3_unit2_relu2)

    stage3_unit2_conv2 = Conv2D(
        filters=256, kernel_size=(3, 3), name="stage3_unit2_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit2_conv2_pad)

    stage3_unit2_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit2_bn3", trainable=False)(
        stage3_unit2_conv2
    )

    stage3_unit2_relu3 = ReLU(name="stage3_unit2_relu3")(stage3_unit2_bn3)

    stage3_unit2_conv3 = Conv2D(
        filters=1024, kernel_size=(1, 1), name="stage3_unit2_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit2_relu3)

    plus8 = Add()([stage3_unit2_conv3, plus7])

    stage3_unit3_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit3_bn1", trainable=False)(plus8)

    stage3_unit3_relu1 = ReLU(name="stage3_unit3_relu1")(stage3_unit3_bn1)

    stage3_unit3_conv1 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage3_unit3_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit3_relu1)

    stage3_unit3_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit3_bn2", trainable=False)(
        stage3_unit3_conv1
    )

    stage3_unit3_relu2 = ReLU(name="stage3_unit3_relu2")(stage3_unit3_bn2)

    stage3_unit3_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage3_unit3_relu2)

    stage3_unit3_conv2 = Conv2D(
        filters=256, kernel_size=(3, 3), name="stage3_unit3_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit3_conv2_pad)

    stage3_unit3_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit3_bn3", trainable=False)(
        stage3_unit3_conv2
    )

    stage3_unit3_relu3 = ReLU(name="stage3_unit3_relu3")(stage3_unit3_bn3)

    stage3_unit3_conv3 = Conv2D(
        filters=1024, kernel_size=(1, 1), name="stage3_unit3_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit3_relu3)

    plus9 = Add()([stage3_unit3_conv3, plus8])

    stage3_unit4_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit4_bn1", trainable=False)(plus9)

    stage3_unit4_relu1 = ReLU(name="stage3_unit4_relu1")(stage3_unit4_bn1)

    stage3_unit4_conv1 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage3_unit4_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit4_relu1)

    stage3_unit4_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit4_bn2", trainable=False)(
        stage3_unit4_conv1
    )

    stage3_unit4_relu2 = ReLU(name="stage3_unit4_relu2")(stage3_unit4_bn2)

    stage3_unit4_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage3_unit4_relu2)

    stage3_unit4_conv2 = Conv2D(
        filters=256, kernel_size=(3, 3), name="stage3_unit4_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit4_conv2_pad)

    stage3_unit4_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit4_bn3", trainable=False)(
        stage3_unit4_conv2
    )

    stage3_unit4_relu3 = ReLU(name="stage3_unit4_relu3")(stage3_unit4_bn3)

    stage3_unit4_conv3 = Conv2D(
        filters=1024, kernel_size=(1, 1), name="stage3_unit4_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit4_relu3)

    plus10 = Add()([stage3_unit4_conv3, plus9])

    stage3_unit5_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit5_bn1", trainable=False)(plus10)

    stage3_unit5_relu1 = ReLU(name="stage3_unit5_relu1")(stage3_unit5_bn1)

    stage3_unit5_conv1 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage3_unit5_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit5_relu1)

    stage3_unit5_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit5_bn2", trainable=False)(
        stage3_unit5_conv1
    )

    stage3_unit5_relu2 = ReLU(name="stage3_unit5_relu2")(stage3_unit5_bn2)

    stage3_unit5_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage3_unit5_relu2)

    stage3_unit5_conv2 = Conv2D(
        filters=256, kernel_size=(3, 3), name="stage3_unit5_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit5_conv2_pad)

    stage3_unit5_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit5_bn3", trainable=False)(
        stage3_unit5_conv2
    )

    stage3_unit5_relu3 = ReLU(name="stage3_unit5_relu3")(stage3_unit5_bn3)

    stage3_unit5_conv3 = Conv2D(
        filters=1024, kernel_size=(1, 1), name="stage3_unit5_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit5_relu3)

    plus11 = Add()([stage3_unit5_conv3, plus10])

    stage3_unit6_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit6_bn1", trainable=False)(plus11)

    stage3_unit6_relu1 = ReLU(name="stage3_unit6_relu1")(stage3_unit6_bn1)

    stage3_unit6_conv1 = Conv2D(
        filters=256, kernel_size=(1, 1), name="stage3_unit6_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit6_relu1)

    stage3_unit6_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit6_bn2", trainable=False)(
        stage3_unit6_conv1
    )

    stage3_unit6_relu2 = ReLU(name="stage3_unit6_relu2")(stage3_unit6_bn2)

    stage3_unit6_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage3_unit6_relu2)

    stage3_unit6_conv2 = Conv2D(
        filters=256, kernel_size=(3, 3), name="stage3_unit6_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit6_conv2_pad)

    stage3_unit6_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage3_unit6_bn3", trainable=False)(
        stage3_unit6_conv2
    )

    stage3_unit6_relu3 = ReLU(name="stage3_unit6_relu3")(stage3_unit6_bn3)

    stage3_unit6_conv3 = Conv2D(
        filters=1024, kernel_size=(1, 1), name="stage3_unit6_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage3_unit6_relu3)

    plus12 = Add()([stage3_unit6_conv3, plus11])

    stage4_unit1_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit1_bn1", trainable=False)(plus12)

    stage4_unit1_relu1 = ReLU(name="stage4_unit1_relu1")(stage4_unit1_bn1)

    stage4_unit1_conv1 = Conv2D(
        filters=512, kernel_size=(1, 1), name="stage4_unit1_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage4_unit1_relu1)

    stage4_unit1_sc = Conv2D(
        filters=2048, kernel_size=(1, 1), name="stage4_unit1_sc", strides=[2, 2], padding="VALID", use_bias=False
    )(stage4_unit1_relu1)

    stage4_unit1_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit1_bn2", trainable=False)(
        stage4_unit1_conv1
    )

    stage4_unit1_relu2 = ReLU(name="stage4_unit1_relu2")(stage4_unit1_bn2)

    stage4_unit1_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage4_unit1_relu2)

    stage4_unit1_conv2 = Conv2D(
        filters=512, kernel_size=(3, 3), name="stage4_unit1_conv2", strides=[2, 2], padding="VALID", use_bias=False
    )(stage4_unit1_conv2_pad)

    ssh_c2_lateral = Conv2D(
        filters=256, kernel_size=(1, 1), name="ssh_c2_lateral", strides=[1, 1], padding="VALID", use_bias=True
    )(stage4_unit1_relu2)

    stage4_unit1_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit1_bn3", trainable=False)(
        stage4_unit1_conv2
    )

    ssh_c2_lateral_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name="ssh_c2_lateral_bn", trainable=False)(
        ssh_c2_lateral
    )

    stage4_unit1_relu3 = ReLU(name="stage4_unit1_relu3")(stage4_unit1_bn3)

    ssh_c2_lateral_relu = ReLU(name="ssh_c2_lateral_relu")(ssh_c2_lateral_bn)

    stage4_unit1_conv3 = Conv2D(
        filters=2048, kernel_size=(1, 1), name="stage4_unit1_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage4_unit1_relu3)

    plus13 = Add()([stage4_unit1_conv3, stage4_unit1_sc])

    stage4_unit2_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit2_bn1", trainable=False)(plus13)

    stage4_unit2_relu1 = ReLU(name="stage4_unit2_relu1")(stage4_unit2_bn1)

    stage4_unit2_conv1 = Conv2D(
        filters=512, kernel_size=(1, 1), name="stage4_unit2_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage4_unit2_relu1)

    stage4_unit2_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit2_bn2", trainable=False)(
        stage4_unit2_conv1
    )

    stage4_unit2_relu2 = ReLU(name="stage4_unit2_relu2")(stage4_unit2_bn2)

    stage4_unit2_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage4_unit2_relu2)

    stage4_unit2_conv2 = Conv2D(
        filters=512, kernel_size=(3, 3), name="stage4_unit2_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage4_unit2_conv2_pad)

    stage4_unit2_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit2_bn3", trainable=False)(
        stage4_unit2_conv2
    )

    stage4_unit2_relu3 = ReLU(name="stage4_unit2_relu3")(stage4_unit2_bn3)

    stage4_unit2_conv3 = Conv2D(
        filters=2048, kernel_size=(1, 1), name="stage4_unit2_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage4_unit2_relu3)

    plus14 = Add()([stage4_unit2_conv3, plus13])

    stage4_unit3_bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit3_bn1", trainable=False)(plus14)

    stage4_unit3_relu1 = ReLU(name="stage4_unit3_relu1")(stage4_unit3_bn1)

    stage4_unit3_conv1 = Conv2D(
        filters=512, kernel_size=(1, 1), name="stage4_unit3_conv1", strides=[1, 1], padding="VALID", use_bias=False
    )(stage4_unit3_relu1)

    stage4_unit3_bn2 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit3_bn2", trainable=False)(
        stage4_unit3_conv1
    )

    stage4_unit3_relu2 = ReLU(name="stage4_unit3_relu2")(stage4_unit3_bn2)

    stage4_unit3_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(stage4_unit3_relu2)

    stage4_unit3_conv2 = Conv2D(
        filters=512, kernel_size=(3, 3), name="stage4_unit3_conv2", strides=[1, 1], padding="VALID", use_bias=False
    )(stage4_unit3_conv2_pad)

    stage4_unit3_bn3 = BatchNormalization(epsilon=1.9999999494757503e-05, name="stage4_unit3_bn3", trainable=False)(
        stage4_unit3_conv2
    )

    stage4_unit3_relu3 = ReLU(name="stage4_unit3_relu3")(stage4_unit3_bn3)

    stage4_unit3_conv3 = Conv2D(
        filters=2048, kernel_size=(1, 1), name="stage4_unit3_conv3", strides=[1, 1], padding="VALID", use_bias=False
    )(stage4_unit3_relu3)

    plus15 = Add()([stage4_unit3_conv3, plus14])

    bn1 = BatchNormalization(epsilon=1.9999999494757503e-05, name="bn1", trainable=False)(plus15)

    relu1 = ReLU(name="relu1")(bn1)

    ssh_c3_lateral = Conv2D(
        filters=256, kernel_size=(1, 1), name="ssh_c3_lateral", strides=[1, 1], padding="VALID", use_bias=True
    )(relu1)

    ssh_c3_lateral_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name="ssh_c3_lateral_bn", trainable=False)(
        ssh_c3_lateral
    )

    ssh_c3_lateral_relu = ReLU(name="ssh_c3_lateral_relu")(ssh_c3_lateral_bn)

    ssh_m3_det_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c3_lateral_relu)

    ssh_m3_det_conv1 = Conv2D(
        filters=256, kernel_size=(3, 3), name="ssh_m3_det_conv1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m3_det_conv1_pad)

    ssh_m3_det_context_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c3_lateral_relu)

    ssh_m3_det_context_conv1 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m3_det_context_conv1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m3_det_context_conv1_pad)

    ssh_c3_up = UpSampling2D(size=(2, 2), interpolation="nearest", name="ssh_c3_up")(ssh_c3_lateral_relu)

    ssh_m3_det_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name="ssh_m3_det_conv1_bn", trainable=False)(
        ssh_m3_det_conv1
    )

    ssh_m3_det_context_conv1_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m3_det_context_conv1_bn", trainable=False
    )(ssh_m3_det_context_conv1)

    x1_shape = tf.shape(ssh_c3_up)
    x2_shape = tf.shape(ssh_c2_lateral_relu)
    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]
    size = [-1, x2_shape[1], x2_shape[2], -1]
    crop0 = tf.slice(ssh_c3_up, offsets, size, "crop0")

    ssh_m3_det_context_conv1_relu = ReLU(name="ssh_m3_det_context_conv1_relu")(ssh_m3_det_context_conv1_bn)

    plus0_v2 = Add()([ssh_c2_lateral_relu, crop0])

    ssh_m3_det_context_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m3_det_context_conv1_relu)

    ssh_m3_det_context_conv2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m3_det_context_conv2", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m3_det_context_conv2_pad)

    ssh_m3_det_context_conv3_1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m3_det_context_conv1_relu)

    ssh_m3_det_context_conv3_1 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m3_det_context_conv3_1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m3_det_context_conv3_1_pad)

    ssh_c2_aggr_pad = ZeroPadding2D(padding=tuple([1, 1]))(plus0_v2)

    ssh_c2_aggr = Conv2D(filters=256, kernel_size=(3, 3), name="ssh_c2_aggr", strides=[1, 1], padding="VALID", use_bias=True)(
        ssh_c2_aggr_pad
    )

    ssh_m3_det_context_conv2_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m3_det_context_conv2_bn", trainable=False
    )(ssh_m3_det_context_conv2)

    ssh_m3_det_context_conv3_1_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m3_det_context_conv3_1_bn", trainable=False
    )(ssh_m3_det_context_conv3_1)

    ssh_c2_aggr_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name="ssh_c2_aggr_bn", trainable=False)(ssh_c2_aggr)

    ssh_m3_det_context_conv3_1_relu = ReLU(name="ssh_m3_det_context_conv3_1_relu")(ssh_m3_det_context_conv3_1_bn)

    ssh_c2_aggr_relu = ReLU(name="ssh_c2_aggr_relu")(ssh_c2_aggr_bn)

    ssh_m3_det_context_conv3_2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m3_det_context_conv3_1_relu)

    ssh_m3_det_context_conv3_2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m3_det_context_conv3_2", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m3_det_context_conv3_2_pad)

    ssh_m2_det_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c2_aggr_relu)

    ssh_m2_det_conv1 = Conv2D(
        filters=256, kernel_size=(3, 3), name="ssh_m2_det_conv1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m2_det_conv1_pad)

    ssh_m2_det_context_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c2_aggr_relu)

    ssh_m2_det_context_conv1 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m2_det_context_conv1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m2_det_context_conv1_pad)

    ssh_m2_red_up = UpSampling2D(size=(2, 2), interpolation="nearest", name="ssh_m2_red_up")(ssh_c2_aggr_relu)

    ssh_m3_det_context_conv3_2_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m3_det_context_conv3_2_bn", trainable=False
    )(ssh_m3_det_context_conv3_2)

    ssh_m2_det_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name="ssh_m2_det_conv1_bn", trainable=False)(
        ssh_m2_det_conv1
    )

    ssh_m2_det_context_conv1_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m2_det_context_conv1_bn", trainable=False
    )(ssh_m2_det_context_conv1)

    x1_shape = tf.shape(ssh_m2_red_up)
    x2_shape = tf.shape(ssh_m1_red_conv_relu)
    offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]
    size = [-1, x2_shape[1], x2_shape[2], -1]
    crop1 = tf.slice(ssh_m2_red_up, offsets, size, "crop1")

    ssh_m3_det_concat = concatenate(
        [ssh_m3_det_conv1_bn, ssh_m3_det_context_conv2_bn, ssh_m3_det_context_conv3_2_bn], 3, name="ssh_m3_det_concat"
    )

    ssh_m2_det_context_conv1_relu = ReLU(name="ssh_m2_det_context_conv1_relu")(ssh_m2_det_context_conv1_bn)

    plus1_v1 = Add()([ssh_m1_red_conv_relu, crop1])

    ssh_m3_det_concat_relu = ReLU(name="ssh_m3_det_concat_relu")(ssh_m3_det_concat)

    ssh_m2_det_context_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m2_det_context_conv1_relu)

    ssh_m2_det_context_conv2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m2_det_context_conv2", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m2_det_context_conv2_pad)

    ssh_m2_det_context_conv3_1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m2_det_context_conv1_relu)

    ssh_m2_det_context_conv3_1 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m2_det_context_conv3_1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m2_det_context_conv3_1_pad)

    ssh_c1_aggr_pad = ZeroPadding2D(padding=tuple([1, 1]))(plus1_v1)

    ssh_c1_aggr = Conv2D(filters=256, kernel_size=(3, 3), name="ssh_c1_aggr", strides=[1, 1], padding="VALID", use_bias=True)(
        ssh_c1_aggr_pad
    )

    face_rpn_cls_score_stride32 = Conv2D(
        filters=4, kernel_size=(1, 1), name="face_rpn_cls_score_stride32", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m3_det_concat_relu)

    inter_1 = concatenate([face_rpn_cls_score_stride32[:, :, :, 0], face_rpn_cls_score_stride32[:, :, :, 1]], axis=1)
    inter_2 = concatenate([face_rpn_cls_score_stride32[:, :, :, 2], face_rpn_cls_score_stride32[:, :, :, 3]], axis=1)
    final = tf.stack([inter_1, inter_2])
    face_rpn_cls_score_reshape_stride32 = tf.transpose(final, (1, 2, 3, 0), name="face_rpn_cls_score_reshape_stride32")

    face_rpn_bbox_pred_stride32 = Conv2D(
        filters=8, kernel_size=(1, 1), name="face_rpn_bbox_pred_stride32", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m3_det_concat_relu)

    face_rpn_landmark_pred_stride32 = Conv2D(
        filters=20, kernel_size=(1, 1), name="face_rpn_landmark_pred_stride32", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m3_det_concat_relu)

    ssh_m2_det_context_conv2_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m2_det_context_conv2_bn", trainable=False
    )(ssh_m2_det_context_conv2)

    ssh_m2_det_context_conv3_1_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m2_det_context_conv3_1_bn", trainable=False
    )(ssh_m2_det_context_conv3_1)

    ssh_c1_aggr_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name="ssh_c1_aggr_bn", trainable=False)(ssh_c1_aggr)

    ssh_m2_det_context_conv3_1_relu = ReLU(name="ssh_m2_det_context_conv3_1_relu")(ssh_m2_det_context_conv3_1_bn)

    ssh_c1_aggr_relu = ReLU(name="ssh_c1_aggr_relu")(ssh_c1_aggr_bn)

    face_rpn_cls_prob_stride32 = Softmax(name="face_rpn_cls_prob_stride32")(face_rpn_cls_score_reshape_stride32)

    input_shape = [tf.shape(face_rpn_cls_prob_stride32)[k] for k in range(4)]
    sz = tf.dtypes.cast(input_shape[1] / 2, dtype=tf.int32)
    inter_1 = face_rpn_cls_prob_stride32[:, 0:sz, :, 0]
    inter_2 = face_rpn_cls_prob_stride32[:, 0:sz, :, 1]
    inter_3 = face_rpn_cls_prob_stride32[:, sz:, :, 0]
    inter_4 = face_rpn_cls_prob_stride32[:, sz:, :, 1]
    final = tf.stack([inter_1, inter_3, inter_2, inter_4])
    face_rpn_cls_prob_reshape_stride32 = tf.transpose(final, (1, 2, 3, 0), name="face_rpn_cls_prob_reshape_stride32")

    ssh_m2_det_context_conv3_2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m2_det_context_conv3_1_relu)

    ssh_m2_det_context_conv3_2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m2_det_context_conv3_2", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m2_det_context_conv3_2_pad)

    ssh_m1_det_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c1_aggr_relu)

    ssh_m1_det_conv1 = Conv2D(
        filters=256, kernel_size=(3, 3), name="ssh_m1_det_conv1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m1_det_conv1_pad)

    ssh_m1_det_context_conv1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_c1_aggr_relu)

    ssh_m1_det_context_conv1 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m1_det_context_conv1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m1_det_context_conv1_pad)

    ssh_m2_det_context_conv3_2_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m2_det_context_conv3_2_bn", trainable=False
    )(ssh_m2_det_context_conv3_2)

    ssh_m1_det_conv1_bn = BatchNormalization(epsilon=1.9999999494757503e-05, name="ssh_m1_det_conv1_bn", trainable=False)(
        ssh_m1_det_conv1
    )

    ssh_m1_det_context_conv1_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m1_det_context_conv1_bn", trainable=False
    )(ssh_m1_det_context_conv1)

    ssh_m2_det_concat = concatenate(
        [ssh_m2_det_conv1_bn, ssh_m2_det_context_conv2_bn, ssh_m2_det_context_conv3_2_bn], 3, name="ssh_m2_det_concat"
    )

    ssh_m1_det_context_conv1_relu = ReLU(name="ssh_m1_det_context_conv1_relu")(ssh_m1_det_context_conv1_bn)

    ssh_m2_det_concat_relu = ReLU(name="ssh_m2_det_concat_relu")(ssh_m2_det_concat)

    ssh_m1_det_context_conv2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m1_det_context_conv1_relu)

    ssh_m1_det_context_conv2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m1_det_context_conv2", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m1_det_context_conv2_pad)

    ssh_m1_det_context_conv3_1_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m1_det_context_conv1_relu)

    ssh_m1_det_context_conv3_1 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m1_det_context_conv3_1", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m1_det_context_conv3_1_pad)

    face_rpn_cls_score_stride16 = Conv2D(
        filters=4, kernel_size=(1, 1), name="face_rpn_cls_score_stride16", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m2_det_concat_relu)

    inter_1 = concatenate([face_rpn_cls_score_stride16[:, :, :, 0], face_rpn_cls_score_stride16[:, :, :, 1]], axis=1)
    inter_2 = concatenate([face_rpn_cls_score_stride16[:, :, :, 2], face_rpn_cls_score_stride16[:, :, :, 3]], axis=1)
    final = tf.stack([inter_1, inter_2])
    face_rpn_cls_score_reshape_stride16 = tf.transpose(final, (1, 2, 3, 0), name="face_rpn_cls_score_reshape_stride16")

    face_rpn_bbox_pred_stride16 = Conv2D(
        filters=8, kernel_size=(1, 1), name="face_rpn_bbox_pred_stride16", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m2_det_concat_relu)

    face_rpn_landmark_pred_stride16 = Conv2D(
        filters=20, kernel_size=(1, 1), name="face_rpn_landmark_pred_stride16", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m2_det_concat_relu)

    ssh_m1_det_context_conv2_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m1_det_context_conv2_bn", trainable=False
    )(ssh_m1_det_context_conv2)

    ssh_m1_det_context_conv3_1_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m1_det_context_conv3_1_bn", trainable=False
    )(ssh_m1_det_context_conv3_1)

    ssh_m1_det_context_conv3_1_relu = ReLU(name="ssh_m1_det_context_conv3_1_relu")(ssh_m1_det_context_conv3_1_bn)

    face_rpn_cls_prob_stride16 = Softmax(name="face_rpn_cls_prob_stride16")(face_rpn_cls_score_reshape_stride16)

    input_shape = [tf.shape(face_rpn_cls_prob_stride16)[k] for k in range(4)]
    sz = tf.dtypes.cast(input_shape[1] / 2, dtype=tf.int32)
    inter_1 = face_rpn_cls_prob_stride16[:, 0:sz, :, 0]
    inter_2 = face_rpn_cls_prob_stride16[:, 0:sz, :, 1]
    inter_3 = face_rpn_cls_prob_stride16[:, sz:, :, 0]
    inter_4 = face_rpn_cls_prob_stride16[:, sz:, :, 1]
    final = tf.stack([inter_1, inter_3, inter_2, inter_4])
    face_rpn_cls_prob_reshape_stride16 = tf.transpose(final, (1, 2, 3, 0), name="face_rpn_cls_prob_reshape_stride16")

    ssh_m1_det_context_conv3_2_pad = ZeroPadding2D(padding=tuple([1, 1]))(ssh_m1_det_context_conv3_1_relu)

    ssh_m1_det_context_conv3_2 = Conv2D(
        filters=128, kernel_size=(3, 3), name="ssh_m1_det_context_conv3_2", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m1_det_context_conv3_2_pad)

    ssh_m1_det_context_conv3_2_bn = BatchNormalization(
        epsilon=1.9999999494757503e-05, name="ssh_m1_det_context_conv3_2_bn", trainable=False
    )(ssh_m1_det_context_conv3_2)

    ssh_m1_det_concat = concatenate(
        [ssh_m1_det_conv1_bn, ssh_m1_det_context_conv2_bn, ssh_m1_det_context_conv3_2_bn], 3, name="ssh_m1_det_concat"
    )

    ssh_m1_det_concat_relu = ReLU(name="ssh_m1_det_concat_relu")(ssh_m1_det_concat)
    face_rpn_cls_score_stride8 = Conv2D(
        filters=4, kernel_size=(1, 1), name="face_rpn_cls_score_stride8", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m1_det_concat_relu)

    inter_1 = concatenate([face_rpn_cls_score_stride8[:, :, :, 0], face_rpn_cls_score_stride8[:, :, :, 1]], axis=1)
    inter_2 = concatenate([face_rpn_cls_score_stride8[:, :, :, 2], face_rpn_cls_score_stride8[:, :, :, 3]], axis=1)
    final = tf.stack([inter_1, inter_2])
    face_rpn_cls_score_reshape_stride8 = tf.transpose(final, (1, 2, 3, 0), name="face_rpn_cls_score_reshape_stride8")

    face_rpn_bbox_pred_stride8 = Conv2D(
        filters=8, kernel_size=(1, 1), name="face_rpn_bbox_pred_stride8", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m1_det_concat_relu)

    face_rpn_landmark_pred_stride8 = Conv2D(
        filters=20, kernel_size=(1, 1), name="face_rpn_landmark_pred_stride8", strides=[1, 1], padding="VALID", use_bias=True
    )(ssh_m1_det_concat_relu)

    face_rpn_cls_prob_stride8 = Softmax(name="face_rpn_cls_prob_stride8")(face_rpn_cls_score_reshape_stride8)

    input_shape = [tf.shape(face_rpn_cls_prob_stride8)[k] for k in range(4)]
    sz = tf.dtypes.cast(input_shape[1] / 2, dtype=tf.int32)
    inter_1 = face_rpn_cls_prob_stride8[:, 0:sz, :, 0]
    inter_2 = face_rpn_cls_prob_stride8[:, 0:sz, :, 1]
    inter_3 = face_rpn_cls_prob_stride8[:, sz:, :, 0]
    inter_4 = face_rpn_cls_prob_stride8[:, sz:, :, 1]
    final = tf.stack([inter_1, inter_3, inter_2, inter_4])
    face_rpn_cls_prob_reshape_stride8 = tf.transpose(final, (1, 2, 3, 0), name="face_rpn_cls_prob_reshape_stride8")

    model = Model(
        inputs=data,
        outputs=[
            face_rpn_cls_prob_reshape_stride32,
            face_rpn_bbox_pred_stride32,
            face_rpn_landmark_pred_stride32,
            face_rpn_cls_prob_reshape_stride16,
            face_rpn_bbox_pred_stride16,
            face_rpn_landmark_pred_stride16,
            face_rpn_cls_prob_reshape_stride8,
            face_rpn_bbox_pred_stride8,
            face_rpn_landmark_pred_stride8,
        ],
    )
    model = load_weights(model)

    return model
